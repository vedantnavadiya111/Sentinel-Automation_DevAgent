# Host folder to mount into containers at /workspace
# On Windows (Docker Desktop), prefer an absolute path, e.g.:
# WORKSPACE_PATH=C:/Users/<you>/code/target_project
WORKSPACE_PATH=./workspace

# n8n settings
N8N_HOST=localhost
N8N_PROTOCOL=http
# Generate a random 32+ char key for production
N8N_ENCRYPTION_KEY=
N8N_LOG_LEVEL=info

# Optional n8n basic auth
N8N_BASIC_AUTH_ACTIVE=false
N8N_BASIC_AUTH_USER=
N8N_BASIC_AUTH_PASSWORD=

# Memory layer settings
MEM0_COLLECTION=sentinel_memories
HF_EMBED_MODEL=multi-qa-MiniLM-L6-cos-v1
HF_EMBED_DIMS=384

# LLM inference (Mem0 LLM provider)
# Groq is supported by Mem0 OSS; set this if you want Mem0-powered summarization/extraction.
GROQ_API_KEY=
GROQ_MODEL=llama-3.3-70b-versatile
